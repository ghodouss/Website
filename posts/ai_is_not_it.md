---
title: Large Language Models do not work the way people think that they do (the result will be bad)
date: 2024-06-23
categories: [LLMs]
---

A [single pixel](https://arxiv.org/abs/1710.08864) can break neural image models.
The same technology is being used to make value judgements.
The scale of investment for the current generation of language models is stunning.
The next generation is an order of magnitude larger.
Money is being burned (literally, they are re-opening coal plants) with the goal of automating white-collar labor.
It will not work.

LLMs are a great fit for certain tasks.
It is helpful as an adaptor for stack overflow examples to your current situation.
I find them very helpful for working with plotting libraries.
Students find it very helpful to avoid learning.
They are excellent at convincing the elderly to make arbitrary bank transfers.

The jump from GPT-3 to GPT-3.5 was by scaling beyond the internet with human labellers.
Given a question and multiple LLM generated answers, the labellers selected the best ones.
Best did not mean true.
Best was the most convincing.

And thus will be born the world's most expensive and convincing [mechanical turk](https://bigthink.com/the-past/mechanical-turk/).


--

Repost from one of my previous blog iterations before I landed on this current deploy setup.

